"use strict";(self.webpackChunkdial=self.webpackChunkdial||[]).push([[5154],{6589:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>r});var t=a(5893),i=a(1151);const s={title:"How to call image-to-text DIAL applications"},o=void 0,l={id:"Cookbook/dial-cookbook/examples/how_to_call_image_to_text_applications",title:"How to call image-to-text DIAL applications",description:"From this notebook, you will learn how to call image-to-text DIAL",source:"@site/docs/Cookbook/dial-cookbook/examples/how_to_call_image_to_text_applications.mdx",sourceDirName:"Cookbook/dial-cookbook/examples",slug:"/Cookbook/dial-cookbook/examples/how_to_call_image_to_text_applications",permalink:"/Cookbook/dial-cookbook/examples/how_to_call_image_to_text_applications",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"How to call image-to-text DIAL applications"},sidebar:"CustomSideBar",previous:{title:"How to call text-to-image DIAL applications",permalink:"/Cookbook/dial-cookbook/examples/how_to_call_text_to_image_applications"},next:{title:"Observability and Monitoring",permalink:"/Observability/"}},c={},r=[{value:"Setup",id:"setup",level:2},{value:"DIAL attachments",id:"dial-attachments",level:2},{value:"Uploading file to the DIAL file storage",id:"uploading-file-to-the-dial-file-storage",level:2},{value:"Using Curl",id:"using-curl",level:2},{value:"Using base64-encoded image data",id:"using-base64-encoded-image-data",level:3},{value:"Using DIAL storage",id:"using-dial-storage",level:3},{value:"Using Python library Requests",id:"using-python-library-requests",level:2},{value:"Using OpenAI Python SDK",id:"using-openai-python-sdk",level:2},{value:"Using LangChain",id:"using-langchain",level:2}];function d(e){const n={a:"a",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["From this notebook, you will learn how to call image-to-text DIAL\napplications via ",(0,t.jsx)(n.a,{href:"https://epam-rail.com/dial_api#/paths/~1openai~1deployments~1%7BDeployment%20Name%7D~1chat~1completions/post",children:"DIAL API\nchat/completions"}),"\ncall."]}),"\n",(0,t.jsxs)(n.div,{className:"jupyter",children:["\n        ",(0,t.jsxs)(n.a,{href:"https://github.com/epam/ai-dial/blob/main/dial-cookbook/examples/how_to_call_image_to_text_applications.ipynb",target:"_blank",rel:"noopener noreferrer",children:[(0,t.jsx)(n.img,{className:"no-zoom",src:"/jupyter.svg",alt:"Jupyter"})," View Jupyter Notebook"]}),"\n    "]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DIAL application"})," is a general term, which encompasses model adapters\nand application with any custom logic."]}),"\n",(0,t.jsx)(n.p,{children:"DIAL currently supports a few image-to-text model adapters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/epam/ai-dial-adapter-openai/",children:"GPT4-Vision"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/epam/ai-dial-adapter-vertexai/",children:"Gemini Pro\nVision"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These models follow the same pattern of usage - they take the chat\nhistory of interactions between user and model, some of the user\nmessages may contain image attachments, which the model takes into\naccount when it generates the response."}),"\n",(0,t.jsx)(n.p,{children:"The typical use case is to attach an image to a message and ask the\nmodel to describe it in the same message."}),"\n",(0,t.jsxs)(n.p,{children:["For example purposes, we are going to use a sample ",(0,t.jsx)(n.code,{children:"image-size"}),"\nimage-to-text application which returns dimensions of an attached image."]}),"\n",(0,t.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 1"}),": install the necessary dependencies and import the libraries\nwe are going to use."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"!pip install requests==2.32.3\n!pip install openai==1.43.0\n!pip install httpx==0.27.2\n!pip install langchain-openai==0.1.23\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import requests\nimport openai\nimport langchain_openai\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 2"}),": if DIAL Core server is already configured and running, set\nenv vars ",(0,t.jsx)(n.code,{children:"DIAL_URL"})," and ",(0,t.jsx)(n.code,{children:"APP_NAME"})," to point to the DIAL Core server and\nthe image-to-text application (or model) you want to use."]}),"\n",(0,t.jsxs)(n.p,{children:["Otherwise, run the ",(0,t.jsx)(n.a,{href:"https://github.com/epam/ai-dial/blob/main/dial-cookbook/docker-compose.yml",children:"docker-compose\nfile"}),"\nin a separate terminal to start the ",(0,t.jsx)(n.strong,{children:"DIAL Core"})," server locally along\nwith a sample ",(0,t.jsx)(n.strong,{children:"image-size"})," application. The DIAL Core will become\navailable at ",(0,t.jsx)(n.code,{children:"http://localhost:8080"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"docker compose up core image-size\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 3"}),": configure ",(0,t.jsx)(n.code,{children:"DIAL_URL"})," and ",(0,t.jsx)(n.code,{children:"APP_NAME"})," env vars. The default\nvalues are configured under the assumption that DIAL Core is running\nlocally via the docker-compose file."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import os\n\ndial_url = os.environ.get("DIAL_URL", "http://localhost:8080")\nos.environ["DIAL_URL"] = dial_url\n\napp_name = os.environ.get("APP_NAME", "image-size")\nos.environ["APP_NAME"] = app_name\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 4"}),": define helpers to read images from disk and display images\nin the notebook:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import base64\n\nfrom IPython.display import Image as IPImage\nfrom IPython.display import display\n\ndef display_base64_image(image_base64):\n    image_binary = base64.b64decode(image_base64)\n    display(IPImage(data=image_binary))\n\ndef read_image_base64(image_path: str) -> str:\n    with open(image_path, "rb") as image_file:\n        image_base64 = base64.b64encode(image_file.read()).decode()\n    return image_base64\n'})}),"\n",(0,t.jsx)(n.h2,{id:"dial-attachments",children:"DIAL attachments"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"render-text"})," application returns an image in its response. The DIAL\nAPI allows to specify a list of attachment files for each message in the\nDIAL request as well as in the message returned in the DIAL response."]}),"\n",(0,t.jsxs)(n.p,{children:["The files attached to the request we call ",(0,t.jsx)(n.strong,{children:"input attachments"}),". They\nare saved at the path\n",(0,t.jsx)(n.code,{children:"messages/{message_idx}/custom_content/attachments/{attachment_idx}"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["And the files attached to the response we call ",(0,t.jsx)(n.strong,{children:"output attachments"}),".\nThey are saved at the path\n",(0,t.jsx)(n.code,{children:"message/custom_content/attachments/{attachment_idx}"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["A single attachment ",(0,t.jsx)(n.em,{children:"(in our case an image attachment)"})," may either\ncontain the content of the image encoded in base64:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "type": "image/png",\n  "title": "Image",\n  "data": "<base64-encoded image data>"\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"or reference the attachment content via a URL:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "type": "image/png",\n  "title": "Image",\n  "url": "<image URL>"\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"The image URL is either 1. a publicly accessible URL or 2. a URL to an\nimage uploaded to the DIAL Core server beforehand."}),"\n",(0,t.jsx)(n.h2,{id:"uploading-file-to-the-dial-file-storage",children:"Uploading file to the DIAL file storage"}),"\n",(0,t.jsx)(n.p,{children:"In order to upload an image to the DIAL file storage, we need first to\nretrieve the user bucket which will be used in all follow-up requests to\nthe DIAL storage:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'bucket = requests.get(\n    f"{dial_url}/v1/bucket", headers={"Api-Key": "dial_api_key"}\n).json()["bucket"]\nprint(f"Bucket: {bucket}")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Bucket: FSWLtFA648cQNf6WfxHZcFzdABKNsTr7ygwQjYbiDi1n\n"})}),"\n",(0,t.jsx)(n.p,{children:"Then upload the image to the bucket via multi-part upload:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import json\n\nwith open("./data/images/square.png", "rb") as file:\n    metadata = requests.put(\n        f"{dial_url}/v1/files/{bucket}/images/square.png",\n        headers={"Api-Key": "dial_api_key"},\n        files={\'file\': (\'square.png\', file, \'image/png\')},\n    ).json()\n    print(f"Metadata: {json.dumps(metadata, indent=2)}")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'Metadata: {\n  "name": "square.png",\n  "parentPath": "images",\n  "bucket": "FSWLtFA648cQNf6WfxHZcFzdABKNsTr7ygwQjYbiDi1n",\n  "url": "files/FSWLtFA648cQNf6WfxHZcFzdABKNsTr7ygwQjYbiDi1n/images/square.png",\n  "nodeType": "ITEM",\n  "resourceType": "FILE",\n  "contentLength": 1082,\n  "contentType": "image/png"\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"The image was uploaded to the DIAL storage and now could be accessed by\nDIAL applications via the URL:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'dial_image_url = metadata["url"]\nprint(f"DIAL Image URL: {dial_image_url}")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"DIAL Image URL: files/FSWLtFA648cQNf6WfxHZcFzdABKNsTr7ygwQjYbiDi1n/images/square.png\n"})}),"\n",(0,t.jsx)(n.p,{children:"The URL is relative to the DIAL Core URL. The application itself will\nresolve the URL to the full URL by prepending the DIAL Core URL to the\nrelative URL."}),"\n",(0,t.jsx)(n.p,{children:"Now we demonstrate how to call the application via DIAL API using either\nDIAL storage to save the image or the base64-encoded image data."}),"\n",(0,t.jsx)(n.h2,{id:"using-curl",children:"Using Curl"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The application deployment is called ",(0,t.jsx)(n.code,{children:"app_name"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["The local DIAL Core server URL is ",(0,t.jsx)(n.code,{children:"dial_url"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["The OpenAI API version we are going to use is ",(0,t.jsx)(n.code,{children:"2023-12-01-preview"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Therefore, the application is accessible via the URL:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"${DIAL_URL}/openai/deployments/${APP_NAME}/chat/completions?api-version=2023-12-01-preview\n"})}),"\n",(0,t.jsx)(n.h3,{id:"using-base64-encoded-image-data",children:"Using base64-encoded image data"}),"\n",(0,t.jsx)(n.p,{children:"The curl command with a singe message with a base64-encoded image is:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'image_base64 = read_image_base64("./data/images/square.png")\n\nos.environ["IMAGE_BASE64"] = image_base64\n\ndisplay_base64_image(image_base64)\n\n!curl -X POST "${DIAL_URL}/openai/deployments/${APP_NAME}/chat/completions?api-version=2023-12-01-preview" \\\n  -H "Api-Key:dial_api_key" \\\n  -H "Content-Type:application/json" \\\n  -d \'{ "messages": [ { "role": "user", "content": "", "custom_content": { "attachments": [ { "type": "image/png", "data": "\'"${IMAGE_BASE64}"\'" } ] } } ] }\'\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:a(4002).Z+"",width:"400",height:"300"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{"choices":[{"index":0,"finish_reason":"stop","message":{"role":"assistant","content":"Size: 400x300px"}}],"usage":null,"id":"ec327e92-0393-4a8d-92a0-9f9589c48dd1","created":1707311404,"object":"chat.completion"}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"using-dial-storage",children:"Using DIAL storage"}),"\n",(0,t.jsxs)(n.p,{children:["Now with the DIAL storage, the request is the same, but instead of\n",(0,t.jsx)(n.code,{children:"data"})," field we provide ",(0,t.jsx)(n.code,{children:"url"})," field with the URL to the uploaded image:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'os.environ["IMAGE_URL"] = dial_image_url\n\n!curl -X POST "${DIAL_URL}/openai/deployments/${APP_NAME}/chat/completions?api-version=2023-12-01-preview" \\\n  -H "Api-Key:dial_api_key" \\\n  -H "Content-Type:application/json" \\\n  -d \'{ "messages": [ { "role": "user", "content": "", "custom_content": { "attachments": [ { "type": "image/png", "url": "\'"${IMAGE_URL}"\'" } ] } } ] }\'\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{"choices":[{"index":0,"finish_reason":"stop","message":{"role":"assistant","content":"Size: 400x300px"}}],"usage":null,"id":"d3fd9bcb-0331-4e5b-8c14-7ccd7e427b45","created":1707311413,"object":"chat.completion"}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"using-python-library-requests",children:"Using Python library Requests"}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s make an HTTP request from Python using ",(0,t.jsx)(n.code,{children:"requests"})," library."]}),"\n",(0,t.jsx)(n.p,{children:"The arguments are identical to the curl command above."}),"\n",(0,t.jsx)(n.p,{children:"From now on, we will demonstrate the DIAL storage use case only. To use\nthe base64-encoded image data, just replace the attachment in the\nrequest:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{"type": "image/png", "url": dial_image_url}\n'})}),"\n",(0,t.jsx)(n.p,{children:"with this one:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{"type": "image/png", "data": image_base64}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s call the application in the ",(0,t.jsx)(n.strong,{children:"non-streaming"})," mode:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'response = requests.post(\n    f"{dial_url}/openai/deployments/{app_name}/chat/completions?api-version=2023-12-01-preview",\n    headers={"Api-Key": "dial_api_key"},\n    json={"messages": [{"role": "user", "content": "", "custom_content": {"attachments": [{"type": "image/png", "url": dial_image_url}]}}]},\n)\nbody = response.json()\ndisplay(body)\n\nmessage = body["choices"][0]["message"]\ncompletion = message["content"]\nprint(f"Completion: {completion!r}")\nassert completion == "Size: 400x300px", "Unexpected completion"\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"{'choices': [{'index': 0,\n   'finish_reason': 'stop',\n   'message': {'role': 'assistant', 'content': 'Size: 400x300px'}}],\n 'usage': None,\n 'id': '1d01a4fb-93a6-49a4-902d-34d6c523d5e0',\n 'created': 1707311423,\n 'object': 'chat.completion'}\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Completion: 'Size: 400x300px'\n"})}),"\n",(0,t.jsxs)(n.p,{children:["When ",(0,t.jsx)(n.strong,{children:"streaming is enabled"}),", the chat completion returns a sequence of\nmessages, each containing a chunk of a generated response:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'response = requests.post(\n    f"{dial_url}/openai/deployments/{app_name}/chat/completions?api-version=2023-12-01-preview",\n    headers={"Api-Key": "dial_api_key"},\n    json={"messages": [{"role": "user", "content": "", "custom_content": {"attachments": [{"type": "image/png", "url": dial_image_url}]}}], "stream": True},\n)\nfor chunk in response.iter_lines():\n    print(chunk)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'b\'data: {"choices":[{"index":0,"finish_reason":null,"delta":{"role":"assistant"}}],"usage":null,"id":"893f5f25-5138-4b9d-9fe9-588b89c70da7","created":1707311431,"object":"chat.completion.chunk"}\'\nb\'\'\nb\'data: {"choices":[{"index":0,"finish_reason":null,"delta":{"content":"Size: 400x300px"}}],"usage":null,"id":"893f5f25-5138-4b9d-9fe9-588b89c70da7","created":1707311431,"object":"chat.completion.chunk"}\'\nb\'\'\nb\'data: {"choices":[{"index":0,"finish_reason":"stop","delta":{}}],"usage":null,"id":"893f5f25-5138-4b9d-9fe9-588b89c70da7","created":1707311431,"object":"chat.completion.chunk"}\'\nb\'\'\nb\'data: [DONE]\'\nb\'\'\n'})}),"\n",(0,t.jsx)(n.h2,{id:"using-openai-python-sdk",children:"Using OpenAI Python SDK"}),"\n",(0,t.jsxs)(n.p,{children:["The DIAL deployment could be called using ",(0,t.jsx)(n.a,{href:"https://pypi.org/project/openai/",children:"OpenAI Python\nSDK"})," as well."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'openai_client = openai.AzureOpenAI(\n    azure_endpoint=dial_url,\n    azure_deployment=app_name,\n    api_key="dial_api_key",\n    api_version="2023-12-01-preview",\n)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s call the application in the ",(0,t.jsx)(n.strong,{children:"non-streaming"})," mode:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'\nchat_completion = openai_client.chat.completions.create(\n    messages=[\n        {\n            "role": "user",\n            "content": "",\n            "custom_content": {"attachments": [{"type": "image/png", "url": dial_image_url}]}\n        }\n    ],\n    model=app_name,\n)\nprint(chat_completion)\nmessage = chat_completion.choices[0].message\ncompletion = message.content\nprint(f"Completion: {completion!r}")\nassert completion == "Size: 400x300px", "Unexpected completion"\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"ChatCompletion(id='cde9f220-ec58-45de-b924-b470ecd50cef', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Size: 400x300px', role='assistant', function_call=None, tool_calls=None))], created=1707311443, model=None, object='chat.completion', system_fingerprint=None, usage=None)\nCompletion: 'Size: 400x300px'\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s call the application in the ",(0,t.jsx)(n.strong,{children:"streaming"})," mode:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'chat_completion = openai_client.chat.completions.create(\n    messages=[\n        {\n            "role": "user",\n            "content": "",\n            "custom_content": {"attachments": [{"type": "image/png", "url": dial_image_url}]}\n        }\n    ],\n    stream=True,\n    model=app_name,\n)\ncompletion = ""\nfor chunk in chat_completion:\n    print(chunk)\n    content = chunk.choices[0].delta.content\n    if content:\n        completion += content\nprint(f"Completion: {completion!r}")\nassert completion == "Size: 400x300px", "Unexpected completion"\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"ChatCompletionChunk(id='29c8af34-1515-4f43-ad90-cab888f67373', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1707311454, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\nChatCompletionChunk(id='29c8af34-1515-4f43-ad90-cab888f67373', choices=[Choice(delta=ChoiceDelta(content='Size: 400x300px', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1707311454, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\nChatCompletionChunk(id='29c8af34-1515-4f43-ad90-cab888f67373', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1707311454, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\nCompletion: 'Size: 400x300px'\n"})}),"\n",(0,t.jsx)(n.h2,{id:"using-langchain",children:"Using LangChain"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.a,{href:"https://pypi.org/project/langchain-openai/",children:"LangChain"})," library ",(0,t.jsx)(n.strong,{children:"is\nnot suitable"})," as a client for image-to-text applications, since\n",(0,t.jsx)(n.code,{children:"langchain-openai"})," ignores additional fields attached to chat messages\nin the request."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from langchain_core.messages import HumanMessage\n\nllm = langchain_openai.AzureChatOpenAI(\n    azure_endpoint=dial_url,\n    azure_deployment=app_name,\n    api_key="dial_api_key",\n    api_version="2023-12-01-preview",\n)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s call the application in the ",(0,t.jsx)(n.strong,{children:"non-streaming"})," mode:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'extra_fields = {"custom_content": {"attachments": [{"type": "image/png", "url": dial_image_url}]}}\n\ntry:\n    llm.generate(messages=[[HumanMessage(content="", additional_kwargs=extra_fields)]])\n\n    raise Exception("Generation didn\'t fail")\nexcept openai.APIError as e:\n    assert e.body["message"] == "No image attachment was found in the last message"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s call the application in the ",(0,t.jsx)(n.strong,{children:"streaming"})," mode:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'try:\n    output = llm.stream(input=[HumanMessage(content="", additional_kwargs=extra_fields)])\n    for chunk in output:\n        print(chunk.dict())\n\n    raise Exception("Generation didn\'t fail")\nexcept openai.APIError as e:\n    assert e.body["message"] == "No image attachment was found in the last message"\n'})})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},4002:(e,n,a)=>{a.d(n,{Z:()=>t});const t="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZAAAAEsCAIAAABi1XKVAAAEAUlEQVR4nO3WsQ2EQBAEwb8X+ae8JICBt7RUFcFYrTkzP4CE//YAgLcEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsICMa3sAH3LObE94NnO2J/AJHhaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAxpnZngDwjocFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQMYNLe4JVeAYhRsAAAAASUVORK5CYII="},1151:(e,n,a)=>{a.d(n,{Z:()=>l,a:()=>o});var t=a(7294);const i={},s=t.createContext(i);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);