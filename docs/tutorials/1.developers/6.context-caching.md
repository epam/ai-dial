# Context Caching

## About Context Caching

Context caching is used to optimize the performance and reduce the operational costs of interacting with large language models (LLMs).

By storing and reusing previously processed data, context caching eliminates the need to reprocess the same information in subsequent requests. This approach is particularly beneficial in scenarios such as multi-turn conversations, complex workflows, or applications requiring repetitive queries, where parts of the request (e.g., system instructions, user prompts, or tool definitions) remain unchanged. 

By leveraging cached data, systems can significantly reduce computation time, improve response efficiency, and lower token usage costs, making it an essential feature for scalable and cost-effective AI implementations.

## Context Caching in DIAL

When context caching is enabled in DIAL, parts of a [chat completion request](https://dialx.ai/dial_api#operation/sendChatCompletionRequest) (e.g., tool definitions, system prompts, or user messages) are saved in Redis cache. This eliminates the need for reprocessing, saving both time and money, especially in large conversations or complex workflows.

### Types of Context Caching

DIAL supports two types of context caching: [automatic](#automatic) and [manual](#manual). These define how cache entries are created and used.

|  | Automatic Caching | Manual Caching |
| :-- | :-- | :-- |
| **User Effort**| Minimal (handled by the system) | High (users must explicitly mark cache breakpoints) |
| **Control** | Limited (system decides breakpoints) | Full (users decide breakpoints) |
| **Use Case** | Multi-turn conversations, general efficiency | Custom workflows, advanced use cases |
| **Dependency on Provider** | Depends on automatic caching support from the provider (e.g., OpenAI) | Works as long as the provider supports caching |
| **Flexibility** | Low (system-driven) | High (user-driven) |

### Hashing

[DIAL Core](/docs/platform/3.core/0.about-core.md) uses hashing to identify and manage cache entries:

* Each [chat completion request](https://dialx.ai/dial_api#operation/sendChatCompletionRequest) is broken into smaller parts (e.g., tools, system messages, or user messages).
* A hashing algorithm generates unique identifiers (hashes) for these parts.
* These hashes are stored in Redis along with metadata, such as the upstream provider and expiration time (TTL).
When a new request is made, [DIAL Core](/docs/platform/3.core/0.about-core.md) checks if any part matches an existing cache entry. If a match is found, the cached data is reused instead of being reprocessed.


### Automatic

> **IMPORTANT**: Ensure the language model supports automatic context caching before enabling it. Not all models support this feature.

Automatic caching happens without explicit user input. The system determines when and where to create cache entries, making it seamless for the user. This is ideal for multi-turn conversations where only new content needs to be processed, while cached content is reused.

##### Prerequisites

Enable automatic caching by setting the [DIAL Core dynamic setting](https://github.com/epam/ai-dial-core?tab=readme-ov-file#dynamic-settings) flag `autoCachingSupported` to `true`. 

##### How it works

When making an initial request to DIAL Core:

1. **Hash Calculation**: DIAL Core calculates a `PREFIX_HASH_MAP` for all prefixes in tools and messages in the [chat completion request](https://dialx.ai/dial_api#operation/sendChatCompletionRequest).
2. **Request Processing**: The request is sent to the model upstream.
3. **Cache Entry Creation**: If the upstream supports caching, the response includes headers:
    - `X-CACHE-BREAKPOINT-PATH`: Specifies the cache breakpoint path.
    - `X-CACHE-UPDATE-EXPIRE-AT`: Indicates the cache expiration time.
4. DIAL Core creates a cache entry in Redis using the `PREFIX_HASH_MAP` and stores the upstream and TTL metadata.

When making subsequent requests:

1. **Hash Lookup**: DIAL Core calculates a `PREFIX_HASH_MAP` and checks Redis for matching prefixes.
2. **Cache Reuse**: If a match is found, DIAL Core sends the request to the model adapter with `X-CACHE-BREAKPOINT-PATH` in the header to reuse cached data.

### Manual

> **IMPORTANT**: Ensure the language model supports context caching before enabling it. Not all models support this feature.

Manual Caching is ideal for scenarios that require a precise control over what parts of a request are cached, especially in complex workflows.

You have full control over where cache breakpoints are placed, making it suitable for highly customized workflows. For example, working with a complex prompt (e.g., a mix of tool definitions, system instructions, and user messages) you can explicitly mark parts of the request for caching to optimize performance.

##### Prerequisites

Enable manual caching by setting the [DIAL Core dynamic setting](https://github.com/epam/ai-dial-core?tab=readme-ov-file#dynamic-settings) flag `cacheSupported` to `true`.

##### How it works

1. **Set Cache Policy**: Add the `X-CACHE-POLICY` header to the [chat completion request](https://dialx.ai/dial_api#operation/sendChatCompletionRequest) to specify the caching strategy:
    - `availability-priority`(default): Prioritizes service availability over cache hits. If the cache upstream is unavailable, the request is routed to another upstream, and a new cache entry is created.
    - `cache-priority`: Prioritizes cache hits over availability. Requests are retried on the same upstream to ensure cache consistency.
2. **Mark Cache Breakpoints**: Add `custom_fields` with `cache_breakpoint` markers in `tools` or `messages`. This explicitly defines where caching should occur.

        ```json
        {
            "messages": [
                {
                    "role": "user",
                    "content": "...",
                    "custom_fields": {
                        "cache_breakpoint": {
                            "expire_at": "2014-10-02T15:01:23Z"
                        }
                    }
                }
            ]
        }

        ...

        {
            "tools": [
                {
                    "custom_fields": {
                        "cache_breakpoint": {}
                    }
                }
            ]
        }

        ```

3. **Hash Calculation**: DIAL Core scans the request for `cache_breakpoint` markers and calculates a hash for the content up to each breakpoint.
4. **Cache Lookup**: DIAL Core checks if the hash already exists in the Redis cache.
    - **If the hash exists in Redis**: The cached data is reused (e.g., routing the request to the same upstream or skipping redundant processing).
    - **If the hash does not exist**: A new cache entry is created in Redis, storing the hash, upstream, and TTL metadata.
5. **Subsequent Requests**: For future requests, DIAL Core recalculates the hash and checks Redis. If a match is found, the cached data is reused, reducing processing time and costs.

