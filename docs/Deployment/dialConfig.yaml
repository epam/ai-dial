global:
  imagePullSecrets:
    - deltix-repo-secret

chat:
  enabled: true

  image:
    tag: 1.7.4

  resources:
    limits:
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 512Mi

  env: # Chat app env variables
    NEXTAUTH_URL: "https://<ChatUrl>" # Public URL of the application. When deploying to production, set the NEXTAUTH_URL environment variable to the canonical URL of your site.
    OPENAI_API_HOST: &proxyUrl "http://<internalProxyUrl>" # AI DIAL Back-end URL
    DEFAULT_MODEL: "gpt-35-turbo" # Default LLM
    OPENAI_API_VERSION: "2023-03-15-preview" # Version of the OpenAI API
    NEXT_PUBLIC_DEFAULT_SYSTEM_PROMPT: "" # The default system prompt
    ENABLED_FEATURES: "conversations-section,prompts-section,top-settings,top-clear-conversation,top-chat-info,top-chat-model-settings,empty-chat-settings,footer,request-api-key,report-an-issue,likes" # A list of UI features
    NEXT_PUBLIC_APP_NAME: "AI Dial" # App name
    AVAILABLE_MODELS_USERS_LIMITATIONS: "" #Example: "amazon.titan-tg1-large=one@email.com,two@email.com,...|ai21.j2-grande-instruct=another@email.com|..."
    AVAILABLE_ADDONS_USERS_LIMITATIONS: "" #Example: "amazon.titan-tg1-large=one@email.com,two@email.com,...|ai21.j2-grande-instruct=another@email.com|..."
    NEXT_PUBLIC_DEFAULT_TEMPERATURE: "" # Default temperature settings [0 1]

  secrets:
    NEXTAUTH_SECRET: "" # A random string used as a ceed for authentication. Used to encrypt the NextAuth.js JWT, and to hash email verification tokens.
    OPENAI_API_KEY: &proxyKey "<somekey>" # Open AI API key
    # Your service provider variables:
    # AUTH_AZURE_AD_CLIENT_ID: ""
    # AUTH_AZURE_AD_TENANT_ID: ""
    # AUTH_AZURE_AD_SECRET: ""
    # AUTH_AZURE_AD_NAME
    # AUTH_GITLAB_CLIENT_ID # Your APP ID at the provider
    # AUTH_GITLAB_SECRET # Your APP secret at the provider
    # AUTH_GITLAB_NAME # Display name in AI DIAL app
    # AUTH_GITLAB_HOST # Provider URL
    # AUTH_GOOGLE_CLIENT_ID
    # AUTH_GOOGLE_SECRET
    # AUTH_AUTH0_CLIENT_ID
    # AUTH_AUTH0_SECRET
    # AUTH_AUTH0_HOST
    # AUTH_AUTH0_NAME
    # AUTH_AUTH0_AUDIENCE
    # AUTH_PING_ID_CLIENT_ID
    # AUTH_PING_ID_SECRET
    # AUTH_PING_ID_HOST
    # AUTH_PING_ID_NAME
    # AUTH_KEYCLOAK_CLIENT_ID
    # AUTH_KEYCLOAK_SECRET
    # AUTH_KEYCLOAK_HOST
    # AUTH_KEYCLOAK_NAME

  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      nginx.ingress.kubernetes.io/proxy-body-size: 100m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 256k
      nginx.ingress.kubernetes.io/proxy-buffering: "on"
      nginx.ingress.kubernetes.io/proxy-buffers-number: "4"
      nginx.ingress.kubernetes.io/proxy-max-temp-file-size: 1024m
    hosts:
      - <ChatUrl>
    tls:
      - secretName: <sslCert>
        hosts:
          - <ChatUrl>

proxy: # AI DIAL Back-end config
  image:
    tag: 0.1.3

  resources:
    limits:
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 512Mi

  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - <ProxyUrl>
    tls:
      - secretName: <sslCert>
        hosts:
          - <ProxyUrl>

  extraVolumes:
    - name: config
      secret:
        secretName: '{{ template "dialProxy.names.fullname" . }}'
        items:
          - key: proxy.config.json
            path: proxy.config.json

  extraVolumeMounts:
    - name: config
      mountPath: "/mnt/secrets-store/proxy.config.json" # Additional config file in the secrets section below
      subPath: proxy.config.json
      readOnly: true

  env:
    proxy.config.files: '["/mnt/secrets-store/proxy.config.json"]' # Path to a back-end config file

  secrets: # Main back-end config
    proxy.config.json: |
      {
        "routes":
        {
          "route-rate": {
            "paths": ["/+v1/rate"],
            "methods": ["POST"],
            "response": {"status": 200}
          }
        },
        "applications":
          "gpt-world": {
            "endpoint": "http://<GPTWorldUrl>/openai/deployments/gpt-world/chat/completions",
            "iconUrl": "",
            "description": "",
            "displayName": "",
            }, 
        },
        "models":
        {
          "gpt-35-turbo": 
          {
            "type": "chat",
            "iconUrl": "",
            "description": "",
            "displayName": "",
            "endpoint": "http://<openaiAdapterUrl>",
            "upstreams":
            [
              {
                "endpoint": "<openAIEndpoint>",
                "key": "<openAIKey>",
              }, 
              {
                "endpoint": "<openAIEndpoint>", 
                "key": "<openAIKey>"
              }
            ]
          },
          "gpt-4": {
            "type": "chat",
            "endpoint": "http://<openaiAdapterUrl>",
            "upstreams": [
              {"endpoint": "<openAIEndpoint>", "key": "<openAIKey"},
              {"endpoint": "<openAIEndpoint>", "key": "<openAIKey"}
            ]
          },
          "gpt-4-32k": {
            "type": "chat",
            "endpoint": "http://<openaiAdapterUrl>",
            "upstreams": [
              {"endpoint": "<openAIEndpoint>", "key": "<openAIKey"},
              {"endpoint": "<openAIEndpoint>", "key": "<openAIKey"}
            ]
          },
          "chat-bison@001": {
            "type": "chat",
            "endpoint": "http://<vertexAdapterUrl>"
          },
          "amazon.titan-tg1-large": {
            "type": "chat",
            "endpoint": "http://<bedrockAdapterUrl>"
          },
          "ai21.j2-grande-instruct": {
            "type": "chat",
            "endpoint": "http://<bedrockAdapterUrl>"
          },
          "ai21.j2-jumbo-instruct": {
            "type": "chat",
            "endpoint": "http://<bedrockAdapterUrl>"
          },
          "anthropic.claude-instant-v1": {
            "type": "chat",
            "endpoint": "http://<bedrockAdapterUrl>"
          },
          "anthropic.claude-v1": {
            "type": "chat",
            "endpoint": "http://<bedrockAdapterUrl>"
          },
          "stability.stable-diffusion-xl": {
            "type": "chat",
            "endpoint": "http://<bedrockAdapterUrl>"
          }
        },
        "keys":
        {
          "<proxyKey>":
          {
            "project": "<proxyKeyDescription>",
            "role": "default",
            "userAuth": false
          }
        },
        "roles":
        {
          "default":
          {
            "limits":
            {
              "gpt-35-turbo":
              {
                "minute": "64000",
                "day": "1000000"
              },
              "gpt-4": {
                "minute": "64000",
                "day": "1000000"
              },
              "gpt-4-32k": {
                "minute": "64000",
                "day": "1000000"
              },
              "chat-bison@001": {
                "minute": "64000",
                "day": "1000000"
              },
              "amazon.titan-tg1-large": {
                "minute": "64000",
                "day": "1000000"
              },
              "ai21.j2-grande-instruct": {
                "minute": "64000",
                "day": "1000000"
              },
              "ai21.j2-jumbo-instruct": {
                "minute": "64000",
                "day": "1000000"
              },
              "anthropic.claude-instant-v1": {
                "minute": "64000",
                "day": "1000000"
              },
              "anthropic.claude-v1": {
                "minute": "64000",
                "day": "1000000"
              },
              "stability.stable-diffusion-xl": {
                "minute": "64000",
                "day": "1000000"
              },
              "gpt-world": {},
            }
          }
        }
      }

  logger:
    config: |
      # vector config in yaml format https://vector.dev/docs/reference/configuration/#example

  # Configuration of custom Adapters

  bedrock: # Configuration of the Adapter for the Bedrock model
    enabled: true

    image:
      tag: 0.5.1 # Docker image of the adapter

    secrets:
      AWS_ACCESS_KEY_ID: "" # Your AWS account credentials
      AWS_SECRET_ACCESS_KEY: "" # Your AWS account credentials

  vertex: # Configuration of the Adapter for the Vertex model
    enabled: true

    image:
      tag: 1.0.2 # Docker image of the adapter

    env:
      GOOGLE_APPLICATION_CREDENTIALS: "/mnt/secrets-store/gcp-ai-proxy-key"
      WEB_CONCURRENCY: "17"
      GCP_PROJECT_ID: ""
      ADAPTER_PROJECT_ID: AI-PROXY
      DEFAULT_REGION: "us-central1"

    secrets:
      gcp-ai-proxy-key: |
        <GCPKey in json format>

    extraVolumes:
      - name: key-file
        secret:
          secretName: '{{ template "dialAdapter.names.fullname" . }}'
          items:
            - key: gcp-ai-proxy-key
              path: gcp-ai-proxy-key

    extraVolumeMounts:
      - name: key-file
        mountPath: "/mnt/secrets-store"
        readOnly: true

  openai: # Configuration of the Adapter for the OpenAI model
    enabled: true

    image:
      tag: 0.1.4 # Docker image of the adapter

  assistant: # Configuration of the Assistant service to work with Addons
    enabled: true

    image:
      tag: 0.1.1

    env:
      OPENAI_API_BASE: *proxyUrl
