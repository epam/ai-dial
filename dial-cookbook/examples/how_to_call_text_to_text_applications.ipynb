{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to call text-to-text DIAL applications\n",
    "\n",
    "This notebook covers how to call text-to-text applications via [DIAL API chat/completions](https://epam-rail.com/dial_api#/paths/~1openai~1deployments~1%7BDeployment%20Name%7D~1chat~1completions/post) call.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install the client libraries, which we will use to call the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../python-notebooks-runner/requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run docker compose in a separate terminal to start the DIAL Core server locally along with the echo application.\n",
    "\n",
    "```sh\n",
    "(cd ..; docker compose up echo core)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure DIAL Core URL: it will be `http://localhost:8080`, if the DIAL Core is run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dial_url = os.environ.get(\"DIAL_URL\", \"http://localhost:8080\")\n",
    "os.environ[\"DIAL_URL\"] = dial_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curl\n",
    "\n",
    "The echo application deployment is called `echo`.\n",
    "\n",
    "The local DIAL Core server URL is `dial_url`.\n",
    "\n",
    "The OpenAI API version we are going to use is `2023-03-15-preview`.\n",
    "\n",
    "Hence the echo application is accessible via the url:\n",
    "\n",
    "```\n",
    "http://${DIAL_URL}/openai/deployments/echo/chat/completions?api-version=2023-03-15-preview\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding curl command with a singe message in the request is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"message\":{\"role\":\"assistant\",\"content\":\"Hello world!\"}}],\"usage\":null,\"id\":\"32d017e4-6626-46ca-9e73-ea74ae739441\",\"created\":1706031917,\"object\":\"chat.completion\"}"
     ]
    }
   ],
   "source": [
    "!curl -X POST \"${DIAL_URL}/openai/deployments/echo/chat/completions?api-version=2023-03-15-preview\" \\\n",
    "  -H \"Api-Key:dial_api_key\" \\\n",
    "  -H \"Content-Type:application/json\" \\\n",
    "  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Hello world!\"}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an HTTP request from Python using `requests` library and make sure the return message matches the message in the request.\n",
    "\n",
    "The arguments are identical to the curl command above.\n",
    "\n",
    "Calling the application in non-streaming mode:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'message': {'role': 'assistant', 'content': 'Hello world!'}}],\n",
       " 'usage': None,\n",
       " 'id': '8abe05db-abce-4b71-815c-8663c0c3f9ca',\n",
       " 'created': 1706031917,\n",
       " 'object': 'chat.completion'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: 'Hello world!'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{dial_url}/openai/deployments/echo/chat/completions?api-version=2023-03-15-preview\",\n",
    "    headers={\"Api-Key\": \"dial_api_key\"},\n",
    "    json={\"messages\": [{\"role\": \"user\", \"content\": \"Hello world!\"}]},\n",
    ")\n",
    "body = response.json()\n",
    "display(body)\n",
    "completion = body[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Hello world!\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When streaming is enabled, the chat completion returns a sequence of messages, each containing a chunk of a generated response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"role\":\"assistant\"}}],\"usage\":null,\"id\":\"a239297f-bc11-44ab-9c5a-fb569f912685\",\"created\":1706031917,\"object\":\"chat.completion.chunk\"}'\n",
      "b''\n",
      "b'data: {\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"content\":\"Hello world!\"}}],\"usage\":null,\"id\":\"a239297f-bc11-44ab-9c5a-fb569f912685\",\"created\":1706031917,\"object\":\"chat.completion.chunk\"}'\n",
      "b''\n",
      "b'data: {\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"delta\":{}}],\"usage\":null,\"id\":\"a239297f-bc11-44ab-9c5a-fb569f912685\",\"created\":1706031917,\"object\":\"chat.completion.chunk\"}'\n",
      "b''\n",
      "b'data: [DONE]'\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    f\"{dial_url}/openai/deployments/echo/chat/completions?api-version=2023-03-15-preview\",\n",
    "    headers={\"Api-Key\": \"dial_api_key\"},\n",
    "    json={\"messages\": [{\"role\": \"user\", \"content\": \"Hello world!\"}], \"stream\": True},\n",
    ")\n",
    "for chunk in response.iter_lines():\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Python SDK\n",
    "\n",
    "The DIAL deployment could be called using [OpenAI Python SDK](https://pypi.org/project/openai/) as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    azure_endpoint=dial_url,\n",
    "    azure_deployment=\"echo\",\n",
    "    api_key=\"dial_api_key\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non-streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='5cd44edb-162c-438f-8ecd-75a2b7564bfc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello world!', role='assistant', function_call=None, tool_calls=None))], created=1706031918, model=None, object='chat.completion', system_fingerprint=None, usage=None)\n",
      "Completion: 'Hello world!'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chat_completion = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello world!\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"echo\",\n",
    ")\n",
    "print(chat_completion)\n",
    "completion = chat_completion.choices[0].message.content\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Hello world!\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='7e55120a-ce86-4232-b099-aacac8edef34', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1706031918, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\n",
      "ChatCompletionChunk(id='7e55120a-ce86-4232-b099-aacac8edef34', choices=[Choice(delta=ChoiceDelta(content='Hello world!', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1706031918, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\n",
      "ChatCompletionChunk(id='7e55120a-ce86-4232-b099-aacac8edef34', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1706031918, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\n",
      "Completion: 'Hello world!'\n"
     ]
    }
   ],
   "source": [
    "chat_completion = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello world!\",\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    model=\"echo\",\n",
    ")\n",
    "completion = \"\"\n",
    "for chunk in chat_completion:\n",
    "    print(chunk)\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content:\n",
    "        completion += content\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Hello world!\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "Or via [LangChain](https://pypi.org/project/langchain-openai/) library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=dial_url,\n",
    "    azure_deployment=\"echo\",\n",
    "    api_key=\"dial_api_key\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In non-streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text='Hello world!', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Hello world!'))]] llm_output={'token_usage': {}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('3673e113-1273-4643-883c-20a3d714048d'))]\n",
      "Completion: 'Hello world!'\n"
     ]
    }
   ],
   "source": [
    "output = llm.generate(messages=[[HumanMessage(content=\"Hello world!\")]])\n",
    "print(output)\n",
    "completion = output.generations[0][0].text\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Hello world!\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '', 'additional_kwargs': {}, 'type': 'AIMessageChunk', 'example': False}\n",
      "{'content': 'Hello world!', 'additional_kwargs': {}, 'type': 'AIMessageChunk', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {}, 'type': 'AIMessageChunk', 'example': False}\n",
      "Completion: 'Hello world!'\n"
     ]
    }
   ],
   "source": [
    "output = llm.stream(input=[HumanMessage(content=\"Hello world!\")])\n",
    "completion = \"\"\n",
    "for chunk in output:\n",
    "    print(chunk.dict())\n",
    "    completion += chunk.content\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Hello world!\", \"Unexpected completion\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
