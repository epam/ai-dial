{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to call text-to-image DIAL applications\n",
    "\n",
    "This notebook covers how to call text-to-image applications via [DIAL API chat/completions](https://epam-rail.com/dial_api#/paths/~1openai~1deployments~1%7BDeployment%20Name%7D~1chat~1completions/post) call.\n",
    "\n",
    "**DIAL application** is a general term, which encompasses model adapters and application with custom logic.\n",
    "\n",
    "DIAL currently supports a few text-to-image model adapters:\n",
    "\n",
    "* [DALL-E-3](https://github.com/epam/ai-dial-adapter-openai/)\n",
    "* [Google Imagen](https://github.com/epam/ai-dial-adapter-vertexai/)\n",
    "* [Stability diffusion](https://github.com/epam/ai-dial-adapter-bedrock/)\n",
    "\n",
    "These models follow the same pattern of usage - they take a last user message as a prompt for image generation and return the generated image in the response.\n",
    "\n",
    "As a simple proxy for these models we'll use an application which prints the given user prompt as an image.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we install the necessary dependencies and import the libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../python-notebooks-runner/requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run docker compose in a separate terminal to start the DIAL Core server locally along with the `image-size` application.\n",
    "\n",
    "`image-size` is a simple image-to-text application which returns dimensions of an attached image.\n",
    "\n",
    "```sh\n",
    "(cd ..; docker compose up core image-size)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now configure DIAL Core URL: it will be `http://localhost:8080`, if the DIAL Core is run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dial_url = os.environ.get(\"DIAL_URL\", \"http://localhost:8080\")\n",
    "os.environ[\"DIAL_URL\"] = dial_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers to read images from disk and display images in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import display\n",
    "\n",
    "def display_base64_image(image_base64):\n",
    "    image_binary = base64.b64decode(image_base64)\n",
    "    display(IPImage(data=image_binary))\n",
    "\n",
    "def read_image_base64(image_path: str) -> str:\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_base64 = base64.b64encode(image_file.read()).decode()\n",
    "    return image_base64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curl\n",
    "\n",
    "The application deployment is called `image-size`.\n",
    "\n",
    "The local DIAL Core server URL is `dial_url`.\n",
    "\n",
    "The OpenAI API version we are going to use is `2023-03-15-preview`.\n",
    "\n",
    "Hence the application is accessible via the url:\n",
    "\n",
    "```\n",
    "http://${DIAL_URL}/openai/deployments/image-size/chat/completions?api-version=2023-03-15-preview\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding curl command with a singe message in the request is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEsCAIAAABi1XKVAAAEAUlEQVR4nO3WsQ2EQBAEwb8X+ae8JICBt7RUFcFYrTkzP4CE//YAgLcEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsICMa3sAH3LObE94NnO2J/AJHhaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAxpnZngDwjocFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQMYNLe4JVeAYhRsAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"message\":{\"role\":\"assistant\",\"content\":\"Size: 400x300px\"}}],\"usage\":null,\"id\":\"410cc421-fe92-4d53-a12d-55dc9a6b67ec\",\"created\":1706099578,\"object\":\"chat.completion\"}"
     ]
    }
   ],
   "source": [
    "image_base64 = read_image_base64(\"./data/images/square.png\")\n",
    "os.environ[\"IMAGE_BASE64\"] = image_base64\n",
    "\n",
    "display_base64_image(image_base64)\n",
    "\n",
    "!curl -X POST \"${DIAL_URL}/openai/deployments/image-size/chat/completions?api-version=2023-03-15-preview\" \\\n",
    "  -H \"Api-Key:dial_api_key\" \\\n",
    "  -H \"Content-Type:application/json\" \\\n",
    "  -d '{ \"messages\": [ { \"role\": \"user\", \"content\": \"\", \"custom_content\": { \"attachments\": [ { \"type\": \"image/png\", \"data\": \"'\"${IMAGE_BASE64}\"'\" } ] } } ] }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an HTTP request from Python using `requests` library and then display the generated image.\n",
    "\n",
    "The arguments are identical to the curl command above.\n",
    "\n",
    "Let's call the application in non-streaming mode first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'message': {'role': 'assistant', 'content': 'Size: 400x300px'}}],\n",
       " 'usage': None,\n",
       " 'id': 'a6e1daab-abc2-455d-8f32-b9cafd7b8c99',\n",
       " 'created': 1706099669,\n",
       " 'object': 'chat.completion'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: 'Size: 400x300px'\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    f\"{dial_url}/openai/deployments/image-size/chat/completions?api-version=2023-03-15-preview\",\n",
    "    headers={\"Api-Key\": \"dial_api_key\"},\n",
    "    json={\"messages\": [{\"role\": \"user\", \"content\": \"\", \"custom_content\": {\"attachments\": [{\"type\": \"image/png\", \"data\": image_base64}]}}]},\n",
    ")\n",
    "body = response.json()\n",
    "display(body)\n",
    "\n",
    "message = body[\"choices\"][0][\"message\"]\n",
    "completion = message[\"content\"]\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Size: 400x300px\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When streaming is enabled, the chat completion returns a sequence of messages, each containing a chunk of a generated response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"role\":\"assistant\"}}],\"usage\":null,\"id\":\"bcc15e5e-66a1-4e11-bc80-e912dbad66c9\",\"created\":1706099696,\"object\":\"chat.completion.chunk\"}'\n",
      "b''\n",
      "b'data: {\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"content\":\"Size: 400x300px\"}}],\"usage\":null,\"id\":\"bcc15e5e-66a1-4e11-bc80-e912dbad66c9\",\"created\":1706099696,\"object\":\"chat.completion.chunk\"}'\n",
      "b''\n",
      "b'data: {\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"delta\":{}}],\"usage\":null,\"id\":\"bcc15e5e-66a1-4e11-bc80-e912dbad66c9\",\"created\":1706099696,\"object\":\"chat.completion.chunk\"}'\n",
      "b''\n",
      "b'data: [DONE]'\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    f\"{dial_url}/openai/deployments/image-size/chat/completions?api-version=2023-03-15-preview\",\n",
    "    headers={\"Api-Key\": \"dial_api_key\"},\n",
    "    json={\"messages\": [{\"role\": \"user\", \"content\": \"\", \"custom_content\": {\"attachments\": [{\"type\": \"image/png\", \"data\": image_base64}]}}], \"stream\": True},\n",
    ")\n",
    "for chunk in response.iter_lines():\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Python SDK\n",
    "\n",
    "The DIAL deployment could be called using [OpenAI Python SDK](https://pypi.org/project/openai/) as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = openai.AzureOpenAI(\n",
    "    azure_endpoint=dial_url,\n",
    "    azure_deployment=\"image-size\",\n",
    "    api_key=\"dial_api_key\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non-streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='7b0af319-75b3-4c37-bc84-69d5574ac27a', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Size: 400x300px', role='assistant', function_call=None, tool_calls=None))], created=1706099744, model=None, object='chat.completion', system_fingerprint=None, usage=None)\n",
      "Completion: 'Size: 400x300px'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chat_completion = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\",\n",
    "            \"custom_content\": {\"attachments\": [{\"type\": \"image/png\", \"data\": image_base64}]}\n",
    "        }\n",
    "    ],\n",
    "    model=\"image-size\",\n",
    ")\n",
    "print(chat_completion)\n",
    "message = chat_completion.choices[0].message\n",
    "completion = message.content\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Size: 400x300px\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='f847cc25-2a53-405c-a0fa-7b98cbb4a44c', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1706099775, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\n",
      "ChatCompletionChunk(id='f847cc25-2a53-405c-a0fa-7b98cbb4a44c', choices=[Choice(delta=ChoiceDelta(content='Size: 400x300px', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1706099775, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\n",
      "ChatCompletionChunk(id='f847cc25-2a53-405c-a0fa-7b98cbb4a44c', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1706099775, model=None, object='chat.completion.chunk', system_fingerprint=None, usage=None)\n",
      "Completion: 'Size: 400x300px'\n"
     ]
    }
   ],
   "source": [
    "chat_completion = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\",\n",
    "            \"custom_content\": {\"attachments\": [{\"type\": \"image/png\", \"data\": image_base64}]}\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    model=\"image-size\",\n",
    ")\n",
    "completion = \"\"\n",
    "for chunk in chat_completion:\n",
    "    print(chunk)\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content:\n",
    "        completion += content\n",
    "print(f\"Completion: {completion!r}\")\n",
    "assert completion == \"Size: 400x300px\", \"Unexpected completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "The [LangChain](https://pypi.org/project/langchain-openai/) library **is not suitable** as a client of text-to-image applications, since `langchain-openai<=0.0.2` ignores the additional fields attached to the response message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = langchain_openai.AzureChatOpenAI(\n",
    "    azure_endpoint=dial_url,\n",
    "    azure_deployment=\"image-size\",\n",
    "    api_key=\"dial_api_key\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In non-streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_fields = {\"custom_content\": {\"attachments\": [{\"type\": \"image/png\", \"data\": image_base64}]}}\n",
    "\n",
    "try:\n",
    "  llm.generate(messages=[[HumanMessage(content=\"\", additional_kwargs=extra_fields)]])\n",
    "\n",
    "  raise Exception(\"Generation didn't fail\")\n",
    "except Exception as e:\n",
    "  assert str(e) == \"Error code: 422 - {'error': {'message': 'No image attachment was found in the last message', 'type': 'runtime_error', 'param': None, 'code': None}}\", \"Unexpected error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    output = llm.stream(input=[HumanMessage(content=\"Hello world!\", additional_kwargs=extra_fields)])\n",
    "    for chunk in output:\n",
    "        print(chunk.dict())\n",
    "\n",
    "    raise Exception(\"Generation didn't fail\")\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Error code: 422 - {'error': {'message': 'No image attachment was found in the last message', 'type': 'runtime_error', 'param': None, 'code': None}}\", \"Unexpected error\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
